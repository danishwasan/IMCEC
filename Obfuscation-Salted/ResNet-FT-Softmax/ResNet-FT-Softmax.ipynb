{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Fine-Tuned+Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## extra imports to set GPU options\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "###################################\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1 # 0.5 for Half\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils import plot_model\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import linecache\n",
    "import sys\n",
    "import h5py\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import RemoteMonitor\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "np.random.seed(1)\n",
    "#from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "\n",
    "from tsne import bh_sne\n",
    "#from tsne.bh_sne import BH_SNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold                                                                                                                       \n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn import svm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as colormap\n",
    "plt.rcParams['image.cmap'] = 'Paired'\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import np_utils\n",
    "#from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.applications.resnet50.ResNet50(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_layer = model.get_layer('avg_pool')\n",
    "\n",
    "x=Dense(4, activation='softmax')(transfer_layer.output)\n",
    "resnet_finetuned = Model(inputs=model.input,\n",
    "                   outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/data/danish/Data/UPX-Packed-And-Unpacked-Samples-train-test/train/'\n",
    "test_path  = '/data/danish/Data/UPX-Packed-And-Unpacked-Samples-train-test/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(224,224)\n",
    "batch_size=64\n",
    "#save_fn='VGG16-Color='+str(input_shape[:])\n",
    "#save_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134 images belonging to 4 classes.\n",
      "Steps for Training\n",
      "\n",
      " 2.09375\n",
      "Labels of samples as integer\n",
      "\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "datagen_train = ImageDataGenerator(\n",
    "      rescale=1./255\n",
    "      #rotation_range=0.1,#180,\n",
    "      #width_shift_range=0.1,\n",
    "      #height_shift_range=0.1,\n",
    "      #shear_range=0.1,\n",
    "      #zoom_range=0.1,#[0.9, 1.5],\n",
    "      #horizontal_flip=True,\n",
    "      #vertical_flip=True,\n",
    "      #fill_mode='nearest'\n",
    "                )\n",
    "\n",
    "generator_train = datagen_train.flow_from_directory(directory=train_path,\n",
    "                                                    target_size=input_shape,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',#binary\n",
    "                                                    #color_mode=\"rgb\",\n",
    "                                                    #save_prefix='Train_Aug',\n",
    "                                                    shuffle=True,\n",
    "                                                    #save_to_dir=save_to_dir,\n",
    "                                                    seed=42)\n",
    "\n",
    "steps_train = generator_train.n/ batch_size\n",
    "print(\"Steps for Training\\n\\n\",steps_train)\n",
    "\n",
    "cls_train = generator_train.classes\n",
    "print(\"Labels of samples as integer\\n\\n\",cls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58 images belonging to 4 classes.\n",
      "Steps for Test\n",
      "\n",
      " 0.90625\n",
      "Labels of samples as integer\n",
      "\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator_test = datagen_test.flow_from_directory(directory=test_path,\n",
    "                                                  target_size=input_shape,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  #color_mode=\"rgb\",\n",
    "                                                  #save_prefix='Test_Aug',\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False,\n",
    "                                                  seed=42)\n",
    "\n",
    "steps_test = generator_test.n / batch_size\n",
    "print(\"Steps for Test\\n\\n\",steps_test)\n",
    "\n",
    "cls_test = generator_test.classes\n",
    "print(\"Labels of samples as integer\\n\\n\",cls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/2 [==========================================] - 20s 7s/step - loss: 1.4763 - acc: 0.2660 - val_loss: 1.1805 - val_acc: 0.6379\n",
      "Epoch 2/50\n",
      "3/2 [==========================================] - 2s 633ms/step - loss: 0.8671 - acc: 0.7287 - val_loss: 1.0421 - val_acc: 0.6724\n",
      "Epoch 3/50\n",
      "3/2 [==========================================] - 2s 819ms/step - loss: 0.6751 - acc: 0.6527 - val_loss: 0.9060 - val_acc: 0.6207\n",
      "Epoch 4/50\n",
      "3/2 [==========================================] - 2s 715ms/step - loss: 0.3264 - acc: 0.8846 - val_loss: 0.8667 - val_acc: 0.6552\n",
      "Epoch 5/50\n",
      "3/2 [==========================================] - 2s 731ms/step - loss: 0.2919 - acc: 0.8757 - val_loss: 0.8146 - val_acc: 0.7241\n",
      "Epoch 6/50\n",
      "3/2 [==========================================] - 3s 861ms/step - loss: 0.2385 - acc: 0.9538 - val_loss: 0.7969 - val_acc: 0.7069\n",
      "Epoch 7/50\n",
      "3/2 [==========================================] - 3s 896ms/step - loss: 0.1856 - acc: 0.9654 - val_loss: 0.7779 - val_acc: 0.7069\n",
      "Epoch 8/50\n",
      "3/2 [==========================================] - 2s 794ms/step - loss: 0.1991 - acc: 0.9769 - val_loss: 0.7356 - val_acc: 0.7414\n",
      "Epoch 9/50\n",
      "3/2 [==========================================] - 3s 928ms/step - loss: 0.1446 - acc: 0.9449 - val_loss: 0.6534 - val_acc: 0.7586\n",
      "Epoch 10/50\n",
      "3/2 [==========================================] - 2s 795ms/step - loss: 0.0975 - acc: 0.9827 - val_loss: 0.5780 - val_acc: 0.7759\n",
      "Epoch 11/50\n",
      "3/2 [==========================================] - 3s 890ms/step - loss: 0.1097 - acc: 0.9885 - val_loss: 0.5044 - val_acc: 0.7931\n",
      "Epoch 12/50\n",
      "3/2 [==========================================] - 2s 753ms/step - loss: 0.1788 - acc: 0.9507 - val_loss: 0.4740 - val_acc: 0.8103\n",
      "Epoch 13/50\n",
      "3/2 [==========================================] - 3s 904ms/step - loss: 0.1662 - acc: 0.9507 - val_loss: 0.4960 - val_acc: 0.8276\n",
      "Epoch 14/50\n",
      "3/2 [==========================================] - 3s 1s/step - loss: 0.0649 - acc: 0.9942 - val_loss: 0.5155 - val_acc: 0.8103\n",
      "Epoch 15/50\n",
      "3/2 [==========================================] - 2s 638ms/step - loss: 0.0715 - acc: 0.9942 - val_loss: 0.5427 - val_acc: 0.7931\n",
      "Epoch 16/50\n",
      "3/2 [==========================================] - 2s 768ms/step - loss: 0.0577 - acc: 0.9942 - val_loss: 0.5847 - val_acc: 0.7931\n",
      "Epoch 17/50\n",
      "3/2 [==========================================] - 2s 799ms/step - loss: 0.1023 - acc: 0.9942 - val_loss: 0.5818 - val_acc: 0.7586\n",
      "Epoch 18/50\n",
      "3/2 [==========================================] - 2s 777ms/step - loss: 0.0602 - acc: 0.9942 - val_loss: 0.5707 - val_acc: 0.7759\n",
      "Epoch 19/50\n",
      "3/2 [==========================================] - 3s 860ms/step - loss: 0.0954 - acc: 0.9507 - val_loss: 0.5351 - val_acc: 0.7931\n",
      "Epoch 20/50\n",
      "3/2 [==========================================] - 3s 849ms/step - loss: 0.0545 - acc: 0.9942 - val_loss: 0.5159 - val_acc: 0.7931\n",
      "Epoch 21/50\n",
      "3/2 [==========================================] - 3s 855ms/step - loss: 0.0804 - acc: 0.9507 - val_loss: 0.5044 - val_acc: 0.8103\n",
      "Epoch 22/50\n",
      "3/2 [==========================================] - 3s 868ms/step - loss: 0.0868 - acc: 0.9565 - val_loss: 0.5080 - val_acc: 0.8103\n",
      "Epoch 23/50\n",
      "3/2 [==========================================] - 3s 860ms/step - loss: 0.0385 - acc: 0.9942 - val_loss: 0.5328 - val_acc: 0.8103\n",
      "Epoch 24/50\n",
      "3/2 [==========================================] - 2s 733ms/step - loss: 0.1146 - acc: 0.9072 - val_loss: 0.5686 - val_acc: 0.7931\n",
      "Epoch 25/50\n",
      "3/2 [==========================================] - 3s 893ms/step - loss: 0.0288 - acc: 0.9942 - val_loss: 0.5978 - val_acc: 0.7586\n",
      "Epoch 26/50\n",
      "3/2 [==========================================] - 3s 910ms/step - loss: 0.2272 - acc: 0.8636 - val_loss: 0.5975 - val_acc: 0.7586\n",
      "Epoch 27/50\n",
      "3/2 [==========================================] - 3s 835ms/step - loss: 0.0676 - acc: 1.0000 - val_loss: 0.5730 - val_acc: 0.7759\n",
      "Epoch 28/50\n",
      "3/2 [==========================================] - 3s 917ms/step - loss: 0.1852 - acc: 0.9072 - val_loss: 0.5359 - val_acc: 0.7759\n",
      "Epoch 29/50\n",
      "3/2 [==========================================] - 3s 840ms/step - loss: 0.1427 - acc: 0.9507 - val_loss: 0.5285 - val_acc: 0.7759\n",
      "Epoch 30/50\n",
      "3/2 [==========================================] - 2s 783ms/step - loss: 0.0569 - acc: 0.9942 - val_loss: 0.5402 - val_acc: 0.7759\n",
      "Epoch 31/50\n",
      "3/2 [==========================================] - 2s 711ms/step - loss: 0.0442 - acc: 0.9942 - val_loss: 0.5693 - val_acc: 0.7759\n",
      "Epoch 32/50\n",
      "3/2 [==========================================] - 2s 722ms/step - loss: 0.0737 - acc: 0.9885 - val_loss: 0.5994 - val_acc: 0.7759\n",
      "Epoch 33/50\n",
      "3/2 [==========================================] - 3s 840ms/step - loss: 0.0266 - acc: 0.9942 - val_loss: 0.6186 - val_acc: 0.7759\n",
      "Epoch 34/50\n",
      "3/2 [==========================================] - 2s 648ms/step - loss: 0.0480 - acc: 0.9942 - val_loss: 0.6398 - val_acc: 0.7759\n",
      "Epoch 35/50\n",
      "3/2 [==========================================] - 3s 881ms/step - loss: 0.0710 - acc: 0.9942 - val_loss: 0.6634 - val_acc: 0.7759\n",
      "Epoch 36/50\n",
      "3/2 [==========================================] - 2s 743ms/step - loss: 0.0880 - acc: 0.9507 - val_loss: 0.6585 - val_acc: 0.7759\n",
      "Epoch 37/50\n",
      "3/2 [==========================================] - 2s 669ms/step - loss: 0.0228 - acc: 0.9942 - val_loss: 0.6422 - val_acc: 0.7759\n",
      "Epoch 38/50\n",
      "3/2 [==========================================] - 2s 820ms/step - loss: 0.0252 - acc: 0.9942 - val_loss: 0.6221 - val_acc: 0.7759\n",
      "Epoch 39/50\n",
      "3/2 [==========================================] - 2s 800ms/step - loss: 0.0199 - acc: 0.9942 - val_loss: 0.6047 - val_acc: 0.7759\n",
      "Epoch 40/50\n",
      "3/2 [==========================================] - 2s 714ms/step - loss: 0.0667 - acc: 0.9507 - val_loss: 0.5871 - val_acc: 0.7759\n",
      "Epoch 41/50\n",
      "3/2 [==========================================] - 3s 1s/step - loss: 0.0190 - acc: 0.9942 - val_loss: 0.5620 - val_acc: 0.7931\n",
      "Epoch 42/50\n",
      "3/2 [==========================================] - 3s 843ms/step - loss: 0.0339 - acc: 0.9942 - val_loss: 0.5370 - val_acc: 0.7931\n",
      "Epoch 43/50\n",
      "3/2 [==========================================] - 2s 714ms/step - loss: 0.0203 - acc: 0.9942 - val_loss: 0.5203 - val_acc: 0.8103\n",
      "Epoch 44/50\n",
      "3/2 [==========================================] - 2s 808ms/step - loss: 0.0165 - acc: 0.9942 - val_loss: 0.5086 - val_acc: 0.8448\n",
      "Epoch 45/50\n",
      "3/2 [==========================================] - 3s 877ms/step - loss: 0.2082 - acc: 0.9072 - val_loss: 0.4834 - val_acc: 0.8276\n",
      "Epoch 46/50\n",
      "3/2 [==========================================] - 2s 663ms/step - loss: 0.0637 - acc: 0.9942 - val_loss: 0.4586 - val_acc: 0.8276\n",
      "Epoch 47/50\n",
      "3/2 [==========================================] - 2s 733ms/step - loss: 0.0302 - acc: 0.9942 - val_loss: 0.4459 - val_acc: 0.8276\n",
      "Epoch 48/50\n",
      "3/2 [==========================================] - 3s 843ms/step - loss: 0.0336 - acc: 1.0000 - val_loss: 0.4447 - val_acc: 0.8276\n",
      "Epoch 49/50\n",
      "3/2 [==========================================] - 3s 863ms/step - loss: 0.1502 - acc: 0.9449 - val_loss: 0.4639 - val_acc: 0.8276\n",
      "Epoch 50/50\n",
      "3/2 [==========================================] - 3s 878ms/step - loss: 0.0890 - acc: 0.9507 - val_loss: 0.4768 - val_acc: 0.8103\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.001, decay=0.01, momentum=0.9)\n",
    "\n",
    "resnet_finetuned.compile(optimizer=sgd,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = resnet_finetuned.fit_generator(generator=generator_train,\n",
    "                                epochs=50,\n",
    "                                steps_per_epoch=steps_train,\n",
    "                                validation_data=generator_test,\n",
    "                                validation_steps=steps_test\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_finetuned.save(\"ResNet50-FT-Model(loss=SGD).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# write Traning History to a file\n",
    "output = open('ResNet50-FT-Softmax-history.pkl', 'wb')\n",
    "pickle.dump(history.history, output)\n",
    "output.close()\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Traning History back from the file\n",
    "pkl_file = open('ResNet50-FT-Softmax-history.pkl', 'rb')\n",
    "history = pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "acc: 81.03%\n"
     ]
    }
   ],
   "source": [
    "scores = resnet_finetuned.evaluate_generator(generator_test, verbose=1)# steps_test, max_queue_size=10, workers=1, use_multiprocessing=False,verbose=1)\n",
    "print(\"%s: %.2f%%\" % (resnet_finetuned.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "resnet_finetuned = load_model(\"ResNet50-FT-Model(loss=SGD).h5\")\n",
    "#resnet_finetuned.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = resnet_finetuned.evaluate_generator(generator_test, verbose=1)# steps_test, max_queue_size=10, workers=1, use_multiprocessing=False,verbose=1)\n",
    "print(\"%s: %.2f%%\" % (resnet_finetuned.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = resnet_finetuned.predict_generator(generator_test, verbose=1)\n",
    "cls_pred = np.argmax(cls_pred, axis=1)\n",
    "print(cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('ResNet-FT-Softmax-pred).pkl', 'wb')\n",
    "pickle.dump(cls_pred, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycm import ConfusionMatrix\n",
    "\n",
    "CM_ResNet_FT_Softmax = ConfusionMatrix(cls_test,cls_pred)\n",
    "\n",
    "file = open('CM_ResNet_FT_Softmax.pkl', 'wb')\n",
    "pickle.dump(CM_ResNet_FT_Softmax, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('CM_ResNet_FT_Softmax.pkl', 'rb')\n",
    "CM_ResNet_FT_Softmax = pickle.load(file)\n",
    "file.close()\n",
    "CM_ResNet_FT_Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fams = list(generator_train.class_indices.keys())\n",
    "list_fams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "#print(confusion_matrix(cls_test,cls_pred))  \n",
    "print(classification_report(cls_test,cls_pred,target_names=list_fams)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "# define example\n",
    "Y_pred = cls_pred\n",
    "\n",
    "# one hot encode\n",
    "Y_pred = to_categorical(Y_pred)\n",
    "print(Y_pred.shape)\n",
    "# invert encoding\n",
    "#inverted = argmax(encoded[0])\n",
    "#print(inverted)\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "# define example\n",
    "Y_test = cls_test\n",
    "\n",
    "# one hot encode\n",
    "Y_test = to_categorical(Y_test)\n",
    "print(Y_test.shape)\n",
    "# invert encoding\n",
    "#inverted = argmax(encoded[0])\n",
    "#print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(4):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], Y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test.ravel(), Y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(4)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(4):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= 4\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "\n",
    "# Plot all ROC curves\n",
    "#plt.figure()\n",
    "#plt.figure(figsize = (25,9))\n",
    "\n",
    "#plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "#         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "#               ''.format(roc_auc[\"micro\"]),\n",
    "#         color='deeppink', marker=11, linewidth=1)\n",
    "\n",
    "#plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "#         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "#               ''.format(roc_auc[\"macro\"]),\n",
    "#         color='navy', marker=5, linewidth=1)\n",
    "\n",
    "\n",
    "colormap = plt.cm.gist_ncar #nipy_spectral, Set1,Paired  \n",
    "colorst = [colormap(i) for i in np.linspace(0, 0.9,25)]  \n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(4), colors):\n",
    "    plt.plot(fpr[i], tpr[i], lw=0.9,\n",
    "             label='ROC curve of Family {0} (area = {1:0.2f})'\n",
    "             ''.format(list_fams[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive')\n",
    "plt.ylabel('True Positive')\n",
    "plt.title('ROC for VGG16-Fine-tuned+Softmax')\n",
    "plt.legend(loc=\"lower right\", fontsize='small')\n",
    "plt.savefig('Receiver Operating Characteristic for VGG16-FT+Softmax.png', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cls_pred):\n",
    "    \n",
    "    \n",
    "    \n",
    "    cm = confusion_matrix(y_true=cls_test, y_pred=cls_pred)\n",
    "    \n",
    "    cm=cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
    "    \n",
    "    figure = plt.gcf()\n",
    "    figure.set_size_inches(20, 12)\n",
    "    sns.set(font_scale=1.25)\n",
    "    hm = sns.heatmap(cm, cbar=True, annot=True, square=True,\n",
    "                 annot_kws={'size': 9}, linewidth = 0.1,\n",
    "                 yticklabels=list_fams, xticklabels=list_fams)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.savefig('ResNet-FT-softmax-Confusion-matrix(loss=SGD).png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix(cls_pred=cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM_ResNet_FT_Softmax.ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
