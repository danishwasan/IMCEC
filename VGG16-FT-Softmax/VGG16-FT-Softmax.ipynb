{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Fine-Tuned+Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "\n",
    "# No GPU found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## extra imports to set GPU options\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "###################################\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1 # 0.5 for Half\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils import plot_model\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import linecache\n",
    "import sys\n",
    "import h5py\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import RemoteMonitor\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "np.random.seed(1)\n",
    "#from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "\n",
    "from tsne import bh_sne\n",
    "#from tsne.bh_sne import BH_SNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold                                                                                                                       \n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn import svm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as colormap\n",
    "plt.rcParams['image.cmap'] = 'Paired'\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import np_utils\n",
    "#from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('/data/danish/ImgProPython/TensorFlow-Tutorials/Ensemble-Networks/IMCEC(Paper Expriments)/Computer-and-Security(IMCEC-version1)/list_fams.pkl', 'rb')\n",
    "list_fams = pickle.load(file)\n",
    "file.close()\n",
    "len(list_fams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_shape=(224,224,3), classes=1000)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_layer = model.get_layer('fc2')\n",
    "\n",
    "x=Dense(25, activation='softmax')(transfer_layer.output)\n",
    "CNN = Model(inputs=model.input,\n",
    "                   outputs=x)\n",
    "#CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/data/danish/Data/Malimg-Gray-25-Families/Malimg_Grayscale_train/'\n",
    "test_path  = '/data/danish/Data/Malimg-Gray-25-Families/Malimg_Grayscale_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(224,224)\n",
    "batch_size=64\n",
    "#save_fn='VGG16-Color='+str(input_shape[:])\n",
    "#save_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6527 images belonging to 25 classes.\n",
      "Steps for Training\n",
      "\n",
      " 101.984375\n",
      "Labels of samples as integer\n",
      "\n",
      " [ 0  0  0 ..., 24 24 24]\n"
     ]
    }
   ],
   "source": [
    "datagen_train = ImageDataGenerator(\n",
    "      rescale=1./255\n",
    "      #rotation_range=0.1,#180,\n",
    "      #width_shift_range=0.1,\n",
    "      #height_shift_range=0.1,\n",
    "      #shear_range=0.1,\n",
    "      #zoom_range=0.1,#[0.9, 1.5],\n",
    "      #horizontal_flip=True,\n",
    "      #vertical_flip=True,\n",
    "      #fill_mode='nearest'\n",
    "                )\n",
    "\n",
    "generator_train = datagen_train.flow_from_directory(directory=train_path,\n",
    "                                                    target_size=input_shape,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',#binary\n",
    "                                                    #color_mode=\"rgb\",\n",
    "                                                    #save_prefix='Train_Aug',\n",
    "                                                    shuffle=True,\n",
    "                                                    #save_to_dir=save_to_dir,\n",
    "                                                    seed=42)\n",
    "\n",
    "steps_train = generator_train.n/ batch_size\n",
    "print(\"Steps for Training\\n\\n\",steps_train)\n",
    "\n",
    "cls_train = generator_train.classes\n",
    "print(\"Labels of samples as integer\\n\\n\",cls_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2812 images belonging to 25 classes.\n",
      "Steps for Test\n",
      "\n",
      " 43.9375\n",
      "Labels of samples as integer\n",
      "\n",
      " [ 0  0  0 ..., 24 24 24]\n"
     ]
    }
   ],
   "source": [
    "datagen_test = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator_test = datagen_test.flow_from_directory(directory=test_path,\n",
    "                                                  target_size=input_shape,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  #color_mode=\"rgb\",\n",
    "                                                  #save_prefix='Test_Aug',\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False,\n",
    "                                                  seed=42)\n",
    "\n",
    "steps_test = generator_test.n / batch_size\n",
    "print(\"Steps for Test\\n\\n\",steps_test)\n",
    "\n",
    "cls_test = generator_test.classes\n",
    "print(\"Labels of samples as integer\\n\\n\",cls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adialer.C',\n",
       " 'Agent.FYI',\n",
       " 'Allaple.A',\n",
       " 'Allaple.L',\n",
       " 'Alueron.gen!J',\n",
       " 'Autorun.K',\n",
       " 'C2LOP.P',\n",
       " 'C2LOP.gen!g',\n",
       " 'Dialplatform.B',\n",
       " 'Dontovo.A',\n",
       " 'Fakerean',\n",
       " 'Instantaccess',\n",
       " 'Lolyda.AA1',\n",
       " 'Lolyda.AA2',\n",
       " 'Lolyda.AA3',\n",
       " 'Lolyda.AT',\n",
       " 'Malex.gen!J',\n",
       " 'ObfuscatorAD',\n",
       " 'Rbot!gen',\n",
       " 'Skintrim.N',\n",
       " 'Swizzorgen!E',\n",
       " 'Swizzorgen!I',\n",
       " 'VB.AT',\n",
       " 'Wintrim.BX',\n",
       " 'Yuner.A']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_fams = list(generator_train.class_indices.keys())\n",
    "list_fams"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sgd = SGD(lr=0.001, decay=0.01, momentum=0.9)\n",
    "\n",
    "CNN.compile(optimizer = sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "102/101 [==============================] - 153s 2s/step - loss: 0.7920 - acc: 0.8070 - val_loss: 0.1462 - val_acc: 0.9570\n",
      "Epoch 2/50\n",
      "102/101 [==============================] - 131s 1s/step - loss: 0.1046 - acc: 0.9694 - val_loss: 0.1000 - val_acc: 0.9691\n",
      "Epoch 3/50\n",
      "102/101 [==============================] - 135s 1s/step - loss: 0.0809 - acc: 0.9747 - val_loss: 0.0954 - val_acc: 0.9673\n",
      "Epoch 4/50\n",
      "102/101 [==============================] - 130s 1s/step - loss: 0.0721 - acc: 0.9759 - val_loss: 0.0943 - val_acc: 0.9691\n",
      "Epoch 5/50\n",
      "102/101 [==============================] - 102s 1s/step - loss: 0.0651 - acc: 0.9787 - val_loss: 0.0898 - val_acc: 0.9705\n",
      "Epoch 6/50\n",
      "102/101 [==============================] - 113s 1s/step - loss: 0.0579 - acc: 0.9792 - val_loss: 0.0816 - val_acc: 0.9716\n",
      "Epoch 7/50\n",
      "102/101 [==============================] - 112s 1s/step - loss: 0.0521 - acc: 0.9802 - val_loss: 0.0836 - val_acc: 0.9694\n",
      "Epoch 8/50\n",
      "102/101 [==============================] - 102s 998ms/step - loss: 0.0448 - acc: 0.9819 - val_loss: 0.0741 - val_acc: 0.9719\n",
      "Epoch 9/50\n",
      "102/101 [==============================] - 109s 1s/step - loss: 0.0381 - acc: 0.9853 - val_loss: 0.0658 - val_acc: 0.9836\n",
      "Epoch 10/50\n",
      "102/101 [==============================] - 107s 1s/step - loss: 0.0350 - acc: 0.9887 - val_loss: 0.0608 - val_acc: 0.9847\n",
      "Epoch 11/50\n",
      "102/101 [==============================] - 105s 1s/step - loss: 0.0264 - acc: 0.9903 - val_loss: 0.0586 - val_acc: 0.9840\n",
      "Epoch 12/50\n",
      "102/101 [==============================] - 111s 1s/step - loss: 0.0213 - acc: 0.9951 - val_loss: 0.0590 - val_acc: 0.9836\n",
      "Epoch 13/50\n",
      "102/101 [==============================] - 110s 1s/step - loss: 0.0183 - acc: 0.9949 - val_loss: 0.0592 - val_acc: 0.9847\n",
      "Epoch 14/50\n",
      "102/101 [==============================] - 110s 1s/step - loss: 0.0164 - acc: 0.9962 - val_loss: 0.0574 - val_acc: 0.9836\n",
      "Epoch 15/50\n",
      "102/101 [==============================] - 109s 1s/step - loss: 0.0146 - acc: 0.9959 - val_loss: 0.0586 - val_acc: 0.9844\n",
      "Epoch 16/50\n",
      "102/101 [==============================] - 96s 937ms/step - loss: 0.0141 - acc: 0.9957 - val_loss: 0.0601 - val_acc: 0.9833\n",
      "Epoch 17/50\n",
      "102/101 [==============================] - 104s 1s/step - loss: 0.0128 - acc: 0.9962 - val_loss: 0.0612 - val_acc: 0.9840\n",
      "Epoch 18/50\n",
      "102/101 [==============================] - 108s 1s/step - loss: 0.0138 - acc: 0.9959 - val_loss: 0.0632 - val_acc: 0.9829\n",
      "Epoch 19/50\n",
      "102/101 [==============================] - 107s 1s/step - loss: 0.0129 - acc: 0.9962 - val_loss: 0.0587 - val_acc: 0.9844\n",
      "Epoch 20/50\n",
      "102/101 [==============================] - 107s 1s/step - loss: 0.0108 - acc: 0.9977 - val_loss: 0.0580 - val_acc: 0.9840\n",
      "Epoch 21/50\n",
      "102/101 [==============================] - 109s 1s/step - loss: 0.0106 - acc: 0.9971 - val_loss: 0.0635 - val_acc: 0.9826\n",
      "Epoch 22/50\n",
      "102/101 [==============================] - 98s 957ms/step - loss: 0.0105 - acc: 0.9975 - val_loss: 0.0602 - val_acc: 0.9844\n",
      "Epoch 23/50\n",
      "102/101 [==============================] - 110s 1s/step - loss: 0.0102 - acc: 0.9980 - val_loss: 0.0665 - val_acc: 0.9822\n",
      "Epoch 24/50\n",
      "102/101 [==============================] - 105s 1s/step - loss: 0.0098 - acc: 0.9977 - val_loss: 0.0615 - val_acc: 0.9847\n",
      "Epoch 25/50\n",
      "102/101 [==============================] - 104s 1s/step - loss: 0.0099 - acc: 0.9980 - val_loss: 0.0635 - val_acc: 0.9833\n",
      "Epoch 26/50\n",
      "102/101 [==============================] - 104s 1s/step - loss: 0.0092 - acc: 0.9982 - val_loss: 0.0694 - val_acc: 0.9822\n",
      "Epoch 27/50\n",
      "102/101 [==============================] - 108s 1s/step - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0627 - val_acc: 0.9840\n",
      "Epoch 28/50\n",
      "102/101 [==============================] - 102s 1s/step - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0676 - val_acc: 0.9822\n",
      "Epoch 29/50\n",
      "102/101 [==============================] - 110s 1s/step - loss: 0.0081 - acc: 0.9983 - val_loss: 0.0630 - val_acc: 0.9844\n",
      "Epoch 30/50\n",
      "102/101 [==============================] - 105s 1s/step - loss: 0.0080 - acc: 0.9977 - val_loss: 0.0628 - val_acc: 0.9840\n",
      "Epoch 31/50\n",
      "102/101 [==============================] - 107s 1s/step - loss: 0.0077 - acc: 0.9985 - val_loss: 0.0659 - val_acc: 0.9844\n",
      "Epoch 32/50\n",
      "102/101 [==============================] - 104s 1s/step - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0640 - val_acc: 0.9844\n",
      "Epoch 33/50\n",
      "102/101 [==============================] - 109s 1s/step - loss: 0.0069 - acc: 0.9986 - val_loss: 0.0659 - val_acc: 0.9854\n",
      "Epoch 34/50\n",
      "102/101 [==============================] - 101s 995ms/step - loss: 0.0070 - acc: 0.9988 - val_loss: 0.0653 - val_acc: 0.9847\n",
      "Epoch 35/50\n",
      "102/101 [==============================] - 110s 1s/step - loss: 0.0071 - acc: 0.9985 - val_loss: 0.0659 - val_acc: 0.9840\n",
      "Epoch 36/50\n",
      "102/101 [==============================] - 104s 1s/step - loss: 0.0066 - acc: 0.9988 - val_loss: 0.0654 - val_acc: 0.9836\n",
      "Epoch 37/50\n",
      "102/101 [==============================] - 105s 1s/step - loss: 0.0066 - acc: 0.9985 - val_loss: 0.0655 - val_acc: 0.9844\n",
      "Epoch 38/50\n",
      "102/101 [==============================] - 104s 1s/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.0654 - val_acc: 0.9840\n",
      "Epoch 39/50\n",
      "102/101 [==============================] - 110s 1s/step - loss: 0.0064 - acc: 0.9985 - val_loss: 0.0661 - val_acc: 0.9847\n",
      "Epoch 40/50\n",
      "102/101 [==============================] - 96s 940ms/step - loss: 0.0061 - acc: 0.9986 - val_loss: 0.0652 - val_acc: 0.9847\n",
      "Epoch 41/50\n",
      "102/101 [==============================] - 105s 1s/step - loss: 0.0061 - acc: 0.9988 - val_loss: 0.0668 - val_acc: 0.9840\n",
      "Epoch 42/50\n",
      "102/101 [==============================] - 107s 1s/step - loss: 0.0058 - acc: 0.9988 - val_loss: 0.0664 - val_acc: 0.9844\n",
      "Epoch 43/50\n",
      "102/101 [==============================] - 105s 1s/step - loss: 0.0059 - acc: 0.9989 - val_loss: 0.0679 - val_acc: 0.9847\n",
      "Epoch 44/50\n",
      "102/101 [==============================] - 108s 1s/step - loss: 0.0057 - acc: 0.9989 - val_loss: 0.0666 - val_acc: 0.9840\n",
      "Epoch 45/50\n",
      "102/101 [==============================] - 106s 1s/step - loss: 0.0055 - acc: 0.9989 - val_loss: 0.0672 - val_acc: 0.9840\n",
      "Epoch 46/50\n",
      "102/101 [==============================] - 110s 1s/step - loss: 0.0054 - acc: 0.9988 - val_loss: 0.0676 - val_acc: 0.9851\n",
      "Epoch 47/50\n",
      "102/101 [==============================] - 106s 1s/step - loss: 0.0050 - acc: 0.9992 - val_loss: 0.0693 - val_acc: 0.9840\n",
      "Epoch 48/50\n",
      "102/101 [==============================] - 105s 1s/step - loss: 0.0053 - acc: 0.9994 - val_loss: 0.0672 - val_acc: 0.9844\n",
      "Epoch 49/50\n",
      "102/101 [==============================] - 102s 1s/step - loss: 0.0051 - acc: 0.9992 - val_loss: 0.0701 - val_acc: 0.9847\n",
      "Epoch 50/50\n",
      "102/101 [==============================] - 111s 1s/step - loss: 0.0052 - acc: 0.9989 - val_loss: 0.0683 - val_acc: 0.9840\n"
     ]
    }
   ],
   "source": [
    "history = CNN.fit_generator(generator=generator_train,\n",
    "                                epochs=50,\n",
    "                                steps_per_epoch=steps_train,\n",
    "                                validation_data=generator_test,\n",
    "                                validation_steps=steps_test\n",
    "                                )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CNN.save(\"VGG16-FT-Model.h5\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#####################################\n",
    "# write Traning History to a file\n",
    "output = open('VGG16-FT-Softmax-history.pkl', 'wb')\n",
    "pickle.dump(history.history, output)\n",
    "output.close()\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Traning History back from the file\n",
    "pkl_file = open('VGG16-FT-Softmax-history.pkl', 'rb')\n",
    "history = pickle.load(pkl_file)\n",
    "pkl_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history) \n",
    "\n",
    "csv_file = 'VGG16-FT-Softmax-history.csv'\n",
    "with open(csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scores = CNN.evaluate_generator(generator_test, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (CNN.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "CNN = load_model(\"VGG16-FT-Model.h5\")\n",
    "#CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 33s 754ms/step\n",
      "acc: 98.51%\n"
     ]
    }
   ],
   "source": [
    "scores = CNN.evaluate_generator(generator_test, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (CNN.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 32s 734ms/step\n",
      "Elasped Time (s) =  32.29834508895874\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.time();\n",
    "\n",
    "cls_pred = CNN.predict_generator(generator_test, verbose=1)\n",
    "\n",
    "toc = time.time();\n",
    "print (\"Elasped Time (s) = \", toc-tic);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = np.argmax(cls_pred, axis=1)\n",
    "print(cls_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "file = open('VGG16-FT+Softmax(pred).pkl', 'wb')\n",
    "pickle.dump(cls_pred, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pycm import ConfusionMatrix\n",
    "CM_VGG16_FT_Softmax = ConfusionMatrix(cls_test,cls_pred)\n",
    "file = open('CM_VGG16_FT_Softmax.pkl', 'wb')\n",
    "pickle.dump(CM_VGG16_FT_Softmax, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pycm.ConfusionMatrix(classes: ['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '3', '4', '5', '6', '7', '8', '9'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write Traning History to a file\n",
    "file = open('CM_VGG16_FT_Softmax.pkl', 'rb')\n",
    "CM_VGG16_FT_Softmax = pickle.load(file)\n",
    "file.close()\n",
    "CM_VGG16_FT_Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Status': True,\n",
       " 'Message': '/data/danish/ImgProPython/TensorFlow-Tutorials/Ensemble-Networks/IMCEC(Paper Expriments)/Computer-and-Security(IMCEC-version1)/VGG16-FT-Softmax/CM_VGG16_FT_Softmax.csv'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM_VGG16_FT_Softmax.save_csv(\"CM_VGG16_FT_Softmax\",address=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Adialer.C       1.00      1.00      1.00        37\n",
      "     Agent.FYI       1.00      1.00      1.00        35\n",
      "     Allaple.A       1.00      1.00      1.00       885\n",
      "     Allaple.L       1.00      1.00      1.00       478\n",
      " Alueron.gen!J       1.00      1.00      1.00        60\n",
      "     Autorun.K       1.00      1.00      1.00        32\n",
      "       C2LOP.P       0.85      0.91      0.88        44\n",
      "   C2LOP.gen!g       0.98      0.92      0.95        60\n",
      "Dialplatform.B       1.00      0.96      0.98        54\n",
      "     Dontovo.A       1.00      1.00      1.00        49\n",
      "      Fakerean       0.98      0.99      0.99       115\n",
      " Instantaccess       1.00      1.00      1.00       130\n",
      "    Lolyda.AA1       0.97      1.00      0.98        64\n",
      "    Lolyda.AA2       1.00      0.96      0.98        56\n",
      "    Lolyda.AA3       1.00      1.00      1.00        37\n",
      "     Lolyda.AT       0.96      1.00      0.98        48\n",
      "   Malex.gen!J       1.00      0.98      0.99        41\n",
      "  ObfuscatorAD       1.00      1.00      1.00        43\n",
      "      Rbot!gen       0.98      0.94      0.96        48\n",
      "    Skintrim.N       1.00      1.00      1.00        24\n",
      "  Swizzorgen!E       0.68      0.72      0.70        39\n",
      "  Swizzorgen!I       0.62      0.60      0.61        40\n",
      "         VB.AT       1.00      1.00      1.00       123\n",
      "    Wintrim.BX       1.00      1.00      1.00        30\n",
      "       Yuner.A       1.00      1.00      1.00       240\n",
      "\n",
      "      accuracy                           0.98      2812\n",
      "     macro avg       0.96      0.96      0.96      2812\n",
      "  weighted avg       0.98      0.98      0.98      2812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "#print(confusion_matrix(cls_test,cls_pred))  \n",
    "print(classification_report(cls_test,cls_pred,target_names=list_fams)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2812, 25, 2)\n",
      "(2812, 25)\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "# define example\n",
    "\n",
    "Y_pred = to_categorical(cls_pred)\n",
    "print(Y_pred.shape)\n",
    "\n",
    "\n",
    "Y_test = to_categorical(cls_test)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (2812, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0e1b8b602d6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \"\"\"\n\u001b[1;32m    621\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 622\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (2812, 2)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(25):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], Y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test.ravel(), Y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(25)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(25):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= 25\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "\n",
    "# Plot all ROC curves\n",
    "#plt.figure()\n",
    "#plt.figure(figsize = (25,9))\n",
    "\n",
    "#plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "#         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "#               ''.format(roc_auc[\"micro\"]),\n",
    "#         color='deeppink', marker=11, linewidth=1)\n",
    "\n",
    "#plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "#         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "#               ''.format(roc_auc[\"macro\"]),\n",
    "#         color='navy', marker=5, linewidth=1)\n",
    "\n",
    "\n",
    "colormap = plt.cm.gist_ncar #nipy_spectral, Set1,Paired  \n",
    "colorst = [colormap(i) for i in np.linspace(0, 0.9,25)]  \n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(25), colors):\n",
    "    plt.plot(fpr[i], tpr[i], lw=0.9,\n",
    "             label='ROC curve of Family {0} (area = {1:0.2f})'\n",
    "             ''.format(list_fams[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC for VGG16-FT+Softmax')\n",
    "#plt.legend(loc=\"lower right\", fontsize='small')\n",
    "plt.savefig('ROC for VGG16-FT+Softmax.png', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cls_pred):\n",
    "    \n",
    "    cls_true = generator_test.classes\n",
    "    \n",
    "    cm = confusion_matrix(y_true=cls_test, y_pred=cls_pred)\n",
    "    \n",
    "    cm=cm.astype('float')/cm.sum(axis=1)[:,np.newaxis]\n",
    "    \n",
    "    figure = plt.gcf()\n",
    "    figure.set_size_inches(20, 12)\n",
    "    sns.set(font_scale=1.25)\n",
    "    hm = sns.heatmap(cm, cbar=True, annot=True, square=True,\n",
    "                 annot_kws={'size': 9}, linewidth = 0.1,\n",
    "                 yticklabels=list_fams, xticklabels=list_fams)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.savefig('VGG16-Fine-tuned-softmax-Confusion-matrix(loss=SGD).png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix(cls_pred=cls_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
