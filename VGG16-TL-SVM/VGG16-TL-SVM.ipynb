{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Transfer Learned + SVM  (NO-PCA and PCA)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "\n",
    "# No GPU found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## extra imports to set GPU options\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "###################################\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1 # 0.5 for Half\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils import plot_model\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import linecache\n",
    "import sys\n",
    "import h5py\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import RemoteMonitor\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "np.random.seed(1)\n",
    "from tsne import bh_sne\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold                                                                                                                       \n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn import svm\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as colormap\n",
    "plt.rcParams['image.cmap'] = 'Paired'\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import np_utils\n",
    "#from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "imagedir = \"/data/danish/Data/IMCEC(Malimg-Benign-Packed)\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cur_dir = os.getcwd()\n",
    "os.chdir(imagedir)  # the parent folder with sub-folders\n",
    "\n",
    "# Get number of samples per family\n",
    "list_fams = sorted(os.listdir(os.getcwd()), key=str.lower)  # vector of strings with family names\n",
    "no_imgs = []  # No. of samples per family\n",
    "for i in range(len(list_fams)):\n",
    "    os.chdir(list_fams[i])\n",
    "    len1 = len(glob.glob('*.*'))  # assuming the images are stored as 'png'\n",
    "    no_imgs.append(len1)\n",
    "    os.chdir('..')\n",
    "num_samples = np.sum(no_imgs)  # total number of all samples\n",
    "\n",
    "# Compute the labels\n",
    "y = np.zeros(num_samples)\n",
    "pos = 0\n",
    "label = 0\n",
    "for i in no_imgs:\n",
    "    print (\"Label:%2d\\tFamily: %15s\\tNumber of images: %d\" % (label, list_fams[label], i))\n",
    "    for j in range(i):\n",
    "        y[pos] = label\n",
    "        pos += 1\n",
    "    label += 1\n",
    "num_classes = label\n",
    "\n",
    "# Compute the features\n",
    "width, height,channels = (224,224,3)\n",
    "X = np.zeros((num_samples, width, height, channels))\n",
    "cnt = 0\n",
    "list_paths = [] # List of image paths\n",
    "print(\"Processing images ...\")\n",
    "for i in range(len(list_fams)):\n",
    "    for img_file in glob.glob(list_fams[i]+'/*.png'):\n",
    "        #print(\"[%d] Processing image: %s\" % (cnt, img_file))\n",
    "        list_paths.append(os.path.join(os.getcwd(),img_file))\n",
    "        img = image.load_img(img_file, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        X[cnt] = x\n",
    "        cnt += 1\n",
    "print(\"Images processed: %d\" %(cnt))\n",
    "\n",
    "\n",
    "os.chdir(cur_dir)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "np.save(\"DatasetX.npy\",X)\n",
    "np.save(\"Datasety.npy\",y)\n",
    "\n",
    "\n",
    "file = open('list_fams.pkl', 'wb')\n",
    "pickle.dump(list_fams, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9339, 224, 224, 3)\n",
      "(9339,)\n"
     ]
    }
   ],
   "source": [
    "X = np.load(\"/data/danish/ImgProPython/TensorFlow-Tutorials/Ensemble-Networks/IMCEC(Paper Expriments)/Computer-and-Security(IMCEC-version1)/DatasetX.npy\")\n",
    "y = np.load(\"/data/danish/ImgProPython/TensorFlow-Tutorials/Ensemble-Networks/IMCEC(Paper Expriments)/Computer-and-Security(IMCEC-version1)/Datasety.npy\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('/data/danish/ImgProPython/TensorFlow-Tutorials/Ensemble-Networks/IMCEC(Paper Expriments)/Computer-and-Security(IMCEC-version1)/list_fams.pkl', 'rb')\n",
    "list_fams = pickle.load(file)\n",
    "file.close()\n",
    "len(list_fams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_shape=(224,224,3), classes=1000)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_layer = model.get_layer('fc2')\n",
    "conv_model = Model(inputs=model.input,\n",
    "                   outputs=transfer_layer.output)\n",
    "#conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VGG16 extracted features from /data/danish/ImgProPython/TensorFlow-Tutorials/Ensemble-Networks/IMCEC(Paper Expriments)/Computer-and-Security(IMCEC-version1)/VGG16-TL-SVM/VGG16-TL-Features.npy ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9339, 4096)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "filename = '/data/danish/ImgProPython/TensorFlow-Tutorials/Ensemble-Networks/IMCEC(Paper Expriments)/Computer-and-Security(IMCEC-version1)/VGG16-TL-SVM/VGG16-TL-Features.npy'\n",
    "if os.path.exists(filename):\n",
    "    print(\"Loading VGG16 extracted features from %s ...\" %(filename))\n",
    "       \n",
    "    vgg16features = np.load(filename)\n",
    "        \n",
    "else:\n",
    "    print(\"Extracting features from VGG16 layers ...\")\n",
    "    tic = time.time();\n",
    "    vgg16features = conv_model.predict(X)\n",
    "    toc = time.time();\n",
    "    print (\"Elasped Time (s) = \", toc-tic);\n",
    "    print(\"Saving VGG16 extracted features into %s ...\" %(filename))\n",
    "    np.save(filename, vgg16features)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "vgg16features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Transfer Learned No-PCA Applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vgg16features, y, test_size=0.301, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2812"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasped Time (s) =  32.156524658203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danish/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.time();\n",
    "\n",
    "top_model = svm.LinearSVC(C=0.01)\n",
    "top_model.fit(X_train,y_train)  # Training\n",
    "\n",
    "toc = time.time();\n",
    "print (\"Elasped Time (s) = \", toc-tic);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acurracy: 0.9868\n",
      "Elasped Time (s) =  0.14617562294006348\n"
     ]
    }
   ],
   "source": [
    "tic = time.time();\n",
    "y_pred = top_model.predict(X_test)  # Testing\n",
    "toc = time.time();\n",
    "\n",
    "print(\"Test acurracy: %.4f\" %(accuracy_score(y_test,y_pred)))\n",
    "\n",
    "print (\"Elasped Time (s) = \", toc-tic);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "file = open('VGG16-TL-SVM(pred).pkl', 'wb')\n",
    "pickle.dump(y_pred, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acurracy: 0.9868\n",
      "Elasped Time (s) =  0.003595113754272461\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.time();\n",
    "\n",
    "file = open('VGG16-TL-SVM(pred).pkl', 'rb')\n",
    "y_pred = pickle.load(file)\n",
    "print(\"Test acurracy: %.4f\" %(accuracy_score(y_test,y_pred)))\n",
    "file.close()\n",
    "\n",
    "toc = time.time();\n",
    "print (\"Elasped Time (s) = \", toc-tic);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycm import ConfusionMatrix\n",
    "CM_VGG16_TL_SVM = ConfusionMatrix(y_test,y_pred)\n",
    "file = open('CM_VGG16_TL_SVM.pkl', 'wb')\n",
    "pickle.dump(CM_VGG16_TL_SVM, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pycm.ConfusionMatrix(classes: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write Traning History to a file\n",
    "file = open('CM_VGG16_TL_SVM.pkl', 'rb')\n",
    "CM_VGG16_TL_SVM = pickle.load(file)\n",
    "file.close()\n",
    "CM_VGG16_TL_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Status': True,\n",
       " 'Message': '/data/danish/ImgProPython/TensorFlow-Tutorials/Ensemble-Networks/IMCEC(Paper Expriments)/Computer-and-Security(IMCEC-version1)/VGG16-TL-SVM/CM_VGG16_TL_SVM.csv'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM_VGG16_TL_SVM.save_csv(\"CM_VGG16_TL_SVM\",address=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9865694157462912"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_test, y_pred, average='weighted')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve for VGG16-TL+SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "Y_pred = to_categorical(y_pred)\n",
    "print(Y_pred.shape)\n",
    "\n",
    "Y_test = to_categorical(y_test)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(25):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], Y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    #print(\"False-Positive-Rate\",argmax(fpr[i],axis=1))\n",
    "    #print(\"True-Positive-Rate\",argmax(tpr[i],axis=1))\n",
    "    #print(\"ROC_AUC\",argmax(roc_auc[i],axis=0))\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test.ravel(), Y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(25)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(25):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= 25\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "\n",
    "# Plot all ROC curves\n",
    "#plt.figure()\n",
    "#plt.figure(figsize = (25,9))\n",
    "\n",
    "#plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "#         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "#               ''.format(roc_auc[\"micro\"]),\n",
    "#         color='deeppink', marker=11, linewidth=1)\n",
    "\n",
    "#plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "#         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "#               ''.format(roc_auc[\"macro\"]),\n",
    "#         color='navy', marker=5, linewidth=1)\n",
    "\n",
    "\n",
    "colormap = plt.cm.gist_ncar #nipy_spectral, Set1,Paired  \n",
    "colorst = [colormap(i) for i in np.linspace(0, 0.9,25)]  \n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(25), colors):\n",
    "    plt.plot(fpr[i], tpr[i], \n",
    "             label='ROC curve of Family {0} (area = {1:0.2f})'\n",
    "             ''.format(list_fams[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC for VGG16-TL+SVM')\n",
    "#plt.legend(loc=\"lower right\", fontsize='small')\n",
    "plt.savefig('ROC for VGG16-TL+SVM.png', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "#print(confusion_matrix(cls_test,cls_pred))  \n",
    "print(classification_report(y_test,y_pred,target_names=list_fams)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(y_test,y_pred)  # Compute confusion matrix \n",
    "\n",
    "\n",
    "print(\"Plotting the confusion matrix normalized\")\n",
    "conf_mat_norm = conf_mat/np.sum(conf_mat,axis=1)  # Normalizing the confusion matrix\n",
    "conf_mat_norm = np.around(conf_mat_norm,decimals=2)  # rounding to display in figure\n",
    "\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(20, 13)\n",
    "sns.set(font_scale=1)\n",
    "hm = sns.heatmap(conf_mat_norm, cbar=True, annot=True, square=True,\n",
    "                 annot_kws={'size': 9}, linewidth = 0.1,\n",
    "                 yticklabels=list_fams, xticklabels=list_fams)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Transfer Learned PCA Applied"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Transfer+SVM using PCA-reduced Features\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=410)\n",
    "\n",
    "transfer_values = vgg16features\n",
    "\n",
    "cls = y\n",
    "\n",
    "print(transfer_values.shape)\n",
    "\n",
    "transfer_values_reduced = pca.fit_transform(transfer_values)\n",
    "\n",
    "print(transfer_values_reduced.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transfer_values_reduced, cls, test_size=0.301, random_state=42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "top_model = svm.LinearSVC(C=0.01)\n",
    "top_model.fit(X_train,y_train)  # Training\n",
    "y_pred = top_model.predict(X_test)  # Testing\n",
    "print(\"Test acurracy: %.4f\" %(accuracy_score(y_test,y_pred)))\n",
    "\n",
    "# write Traning History to a file\n",
    "file = open('VGG16-TL-PCA-SVM(pred).pkl', 'wb')\n",
    "pickle.dump(y_pred, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# read Traning History back from the file\n",
    "file = open('VGG16-TL-PCA-SVM(pred).pkl', 'rb')\n",
    "y_pred = pickle.load(file)\n",
    "print(\"Test acurracy: %.4f\" %(accuracy_score(y_test,y_pred)))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(y_test,y_pred)  # Compute confusion matrix \n",
    "\n",
    "\n",
    "print(\"Plotting the confusion matrix normalized\")\n",
    "conf_mat_norm = conf_mat/np.sum(conf_mat,axis=1)  # Normalizing the confusion matrix\n",
    "conf_mat_norm = np.around(conf_mat_norm,decimals=2)  # rounding to display in figure\n",
    "\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(20, 12)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(conf_mat_norm, cbar=True, annot=True, square=True,\n",
    "                 annot_kws={'size': 9}, linewidth = 0.1,\n",
    "                 yticklabels=list_fams, xticklabels=list_fams)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "#print(confusion_matrix(cls_test,cls_pred))  \n",
    "print(classification_report(y_test,y_pred,target_names=list_fams)) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"Running t-SNE ...\")\n",
    "vis_data = bh_sne(np.float64(transfer_values_reduced), d=2, perplexity=30., theta=0.5, random_state=RandomState(1))\n",
    "\n",
    "print(\"Plotting t-SNE ...\")\n",
    "figure = plt.gcf()\n",
    "figure.set_size_inches(24, 18)\n",
    "plt.scatter(vis_data[:, 0], vis_data[:, 1], c=y, cmap=plt.cm.get_cmap(\"gist_ncar\", len(list_fams)),edgecolors=\"black\")\n",
    "plt.clim(-0.5, len(list_fams)-0.5)\n",
    "cbar = plt.colorbar(ticks=range(len(list_fams)))\n",
    "cbar.ax.set_yticklabels(list_fams)                     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
